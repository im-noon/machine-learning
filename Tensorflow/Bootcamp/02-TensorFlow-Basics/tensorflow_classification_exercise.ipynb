{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('../data/census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 14 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "gender            32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income_bracket    32561 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "census.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(lambda label:int(label == ' >50K'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef label_fix(label):\\n    if label == ' <=50K':\\n        return 0\\n    else:\\n        return 1\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def label_fix(label):\n",
    "    if label == ' <=50K':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method\n",
    "#census['income_bracket'] = census['income_bracket'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = census.drop('income_bracket', axis=1)\n",
    "y_data = census['income_bracket']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import Tensorflow **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=1000)\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=1000)\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=1000)\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=1000)\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship', hash_bucket_size=1000)\n",
    "race = tf.feature_column.categorical_column_with_hash_bucket('race', hash_bucket_size=10000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=1000)\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list('gender',vocabulary_list=[' Male', ' Female'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_workclass = tf.feature_column.embedding_column(workclass, dimension=len(x_data['workclass'].unique()))\n",
    "embedded_education = tf.feature_column.embedding_column(education, dimension=len(x_data['education'].unique()))\n",
    "embedded_marital_status = tf.feature_column.embedding_column(marital_status, dimension=len(x_data['marital_status'].unique()))\n",
    "embedded_occupation = tf.feature_column.embedding_column(occupation, dimension=len(x_data['occupation'].unique()))\n",
    "embedded_relationship = tf.feature_column.embedding_column(relationship, dimension=len(x_data['relationship'].unique()))\n",
    "embedded_race = tf.feature_column.embedding_column(race, dimension=len(x_data['race'].unique()))\n",
    "embedded_native_country = tf.feature_column.embedding_column(native_country, dimension=len(x_data['native_country'].unique()))\n",
    "embedded_gender = tf.feature_column.embedding_column(gender, dimension=len(x_data['gender'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_feat_cols = [age, \n",
    "                    workclass, \n",
    "                    education,\n",
    "                    education_num,\n",
    "                    marital_status,\n",
    "                    occupation, \n",
    "                    relationship, \n",
    "                    race,\n",
    "                    gender,\n",
    "                    capital_gain,\n",
    "                    capital_loss,\n",
    "                    hours_per_week, \n",
    "                    native_country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feat_cols =  [age,\n",
    "                  embedded_workclass, \n",
    "                  embedded_education,\n",
    "                  education_num,\n",
    "                  embedded_marital_status,\n",
    "                  embedded_occupation, \n",
    "                  embedded_relationship, \n",
    "                  embedded_race,\n",
    "                  embedded_gender,\n",
    "                  capital_gain,\n",
    "                  capital_loss,\n",
    "                  hours_per_week, \n",
    "                  embedded_native_country]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_input_fn = tf.estimator.inputs.pandas_input_fn(x=X_train,\n",
    "                                                      y=y_train,\n",
    "                                                      batch_size=100,\n",
    "                                                      num_epochs=None,\n",
    "                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_input_fn = tf.estimator.inputs.pandas_input_fn(x=X_train,\n",
    "                                                   y=y_train,\n",
    "                                                   batch_size=100,\n",
    "                                                   num_epochs=None,\n",
    "                                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x138656f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "linearClassifier = tf.estimator.LinearClassifier(feature_columns=linear_feat_cols, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x138656c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnnClassifier = tf.estimator.DNNClassifier(hidden_units=[13,20,20,13], feature_columns=dnn_feat_cols, n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31474, step = 1\n",
      "INFO:tensorflow:global_step/sec: 15.4219\n",
      "INFO:tensorflow:loss = 281.60962, step = 101 (6.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.7456\n",
      "INFO:tensorflow:loss = 493.96362, step = 201 (3.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.539\n",
      "INFO:tensorflow:loss = 28.274252, step = 301 (3.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.512\n",
      "INFO:tensorflow:loss = 93.00099, step = 401 (3.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0216\n",
      "INFO:tensorflow:loss = 61.989227, step = 501 (4.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2925\n",
      "INFO:tensorflow:loss = 162.3154, step = 601 (4.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3727\n",
      "INFO:tensorflow:loss = 84.22957, step = 701 (4.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9223\n",
      "INFO:tensorflow:loss = 209.88916, step = 801 (4.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.184\n",
      "INFO:tensorflow:loss = 97.75552, step = 901 (4.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1896\n",
      "INFO:tensorflow:loss = 177.90898, step = 1001 (3.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7837\n",
      "INFO:tensorflow:loss = 87.12027, step = 1101 (4.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.4974\n",
      "INFO:tensorflow:loss = 417.64664, step = 1201 (3.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8713\n",
      "INFO:tensorflow:loss = 70.3219, step = 1301 (2.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5805\n",
      "INFO:tensorflow:loss = 260.00507, step = 1401 (4.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4797\n",
      "INFO:tensorflow:loss = 109.87286, step = 1501 (3.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6771\n",
      "INFO:tensorflow:loss = 192.39526, step = 1601 (4.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5664\n",
      "INFO:tensorflow:loss = 197.26755, step = 1701 (4.067 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1349\n",
      "INFO:tensorflow:loss = 50.556236, step = 1801 (3.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6433\n",
      "INFO:tensorflow:loss = 38.150818, step = 1901 (3.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 30.2764\n",
      "INFO:tensorflow:loss = 271.96664, step = 2001 (3.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3523\n",
      "INFO:tensorflow:loss = 113.398605, step = 2101 (3.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1217\n",
      "INFO:tensorflow:loss = 96.312256, step = 2201 (2.916 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2146\n",
      "INFO:tensorflow:loss = 536.8204, step = 2301 (2.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3461\n",
      "INFO:tensorflow:loss = 184.26575, step = 2401 (3.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.6233\n",
      "INFO:tensorflow:loss = 42.41156, step = 2501 (3.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.8252\n",
      "INFO:tensorflow:loss = 390.75623, step = 2601 (3.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3271\n",
      "INFO:tensorflow:loss = 30.91289, step = 2701 (3.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9798\n",
      "INFO:tensorflow:loss = 36.78151, step = 2801 (3.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.1283\n",
      "INFO:tensorflow:loss = 161.44183, step = 2901 (3.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.2925\n",
      "INFO:tensorflow:loss = 86.144196, step = 3001 (3.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8096\n",
      "INFO:tensorflow:loss = 59.943157, step = 3101 (5.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.0804\n",
      "INFO:tensorflow:loss = 85.66469, step = 3201 (6.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.3104\n",
      "INFO:tensorflow:loss = 122.99943, step = 3301 (3.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2711\n",
      "INFO:tensorflow:loss = 81.38226, step = 3401 (3.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8287\n",
      "INFO:tensorflow:loss = 44.20117, step = 3501 (2.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1721\n",
      "INFO:tensorflow:loss = 49.354904, step = 3601 (2.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5129\n",
      "INFO:tensorflow:loss = 82.87156, step = 3701 (2.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6107\n",
      "INFO:tensorflow:loss = 27.444853, step = 3801 (2.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0417\n",
      "INFO:tensorflow:loss = 90.46558, step = 3901 (2.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.9584\n",
      "INFO:tensorflow:loss = 224.42084, step = 4001 (2.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.9387\n",
      "INFO:tensorflow:loss = 48.51001, step = 4101 (2.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6372\n",
      "INFO:tensorflow:loss = 24.536877, step = 4201 (2.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3951\n",
      "INFO:tensorflow:loss = 82.69603, step = 4301 (5.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7209\n",
      "INFO:tensorflow:loss = 32.642014, step = 4401 (8.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.9741\n",
      "INFO:tensorflow:loss = 36.127968, step = 4501 (6.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7201\n",
      "INFO:tensorflow:loss = 30.843475, step = 4601 (6.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.219\n",
      "INFO:tensorflow:loss = 50.898895, step = 4701 (6.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4992\n",
      "INFO:tensorflow:loss = 34.265327, step = 4801 (8.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1361\n",
      "INFO:tensorflow:loss = 67.81431, step = 4901 (9.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6071\n",
      "INFO:tensorflow:loss = 47.413425, step = 5001 (9.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.4379\n",
      "INFO:tensorflow:loss = 33.212105, step = 5101 (8.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.79799\n",
      "INFO:tensorflow:loss = 49.461243, step = 5201 (10.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 13.7539\n",
      "INFO:tensorflow:loss = 27.969074, step = 5301 (7.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6938\n",
      "INFO:tensorflow:loss = 19.489956, step = 5401 (4.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8409\n",
      "INFO:tensorflow:loss = 108.33901, step = 5501 (4.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.8936\n",
      "INFO:tensorflow:loss = 114.287445, step = 5601 (3.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.957\n",
      "INFO:tensorflow:loss = 59.647102, step = 5701 (2.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0733\n",
      "INFO:tensorflow:loss = 31.231392, step = 5801 (2.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2898\n",
      "INFO:tensorflow:loss = 49.550034, step = 5901 (2.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 127.951035, step = 6001 (2.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.803\n",
      "INFO:tensorflow:loss = 31.78439, step = 6101 (2.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.6176\n",
      "INFO:tensorflow:loss = 181.71286, step = 6201 (2.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.9589\n",
      "INFO:tensorflow:loss = 28.141228, step = 6301 (2.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.7733\n",
      "INFO:tensorflow:loss = 43.35981, step = 6401 (2.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.0812\n",
      "INFO:tensorflow:loss = 50.12488, step = 6501 (2.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7206\n",
      "INFO:tensorflow:loss = 44.89504, step = 6601 (2.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.1824\n",
      "INFO:tensorflow:loss = 44.187756, step = 6701 (2.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7264\n",
      "INFO:tensorflow:loss = 97.55087, step = 6801 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.9472\n",
      "INFO:tensorflow:loss = 41.049816, step = 6901 (2.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8358\n",
      "INFO:tensorflow:loss = 34.692467, step = 7001 (2.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4143\n",
      "INFO:tensorflow:loss = 30.189621, step = 7101 (2.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 50.3414\n",
      "INFO:tensorflow:loss = 24.911846, step = 7201 (1.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4177\n",
      "INFO:tensorflow:loss = 77.35569, step = 7301 (2.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8699\n",
      "INFO:tensorflow:loss = 100.41341, step = 7401 (4.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7354\n",
      "INFO:tensorflow:loss = 53.78435, step = 7501 (2.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.8209\n",
      "INFO:tensorflow:loss = 31.017342, step = 7601 (2.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.2016\n",
      "INFO:tensorflow:loss = 39.389854, step = 7701 (2.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.8559\n",
      "INFO:tensorflow:loss = 114.50769, step = 7801 (2.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.7936\n",
      "INFO:tensorflow:loss = 24.458786, step = 7901 (2.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.0397\n",
      "INFO:tensorflow:loss = 36.583103, step = 8001 (2.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8345\n",
      "INFO:tensorflow:loss = 124.64505, step = 8101 (2.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.3229\n",
      "INFO:tensorflow:loss = 44.257828, step = 8201 (3.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2345\n",
      "INFO:tensorflow:loss = 79.383804, step = 8301 (2.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4409\n",
      "INFO:tensorflow:loss = 34.810978, step = 8401 (2.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2992\n",
      "INFO:tensorflow:loss = 57.828377, step = 8501 (2.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.182\n",
      "INFO:tensorflow:loss = 33.001877, step = 8601 (2.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.458\n",
      "INFO:tensorflow:loss = 54.329445, step = 8701 (2.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.0659\n",
      "INFO:tensorflow:loss = 40.579002, step = 8801 (2.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.7528\n",
      "INFO:tensorflow:loss = 28.70949, step = 8901 (2.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5974\n",
      "INFO:tensorflow:loss = 30.72118, step = 9001 (2.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 46.1683\n",
      "INFO:tensorflow:loss = 27.20364, step = 9101 (2.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.2949\n",
      "INFO:tensorflow:loss = 24.639194, step = 9201 (2.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5788\n",
      "INFO:tensorflow:loss = 72.19253, step = 9301 (2.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 42.2666\n",
      "INFO:tensorflow:loss = 47.79341, step = 9401 (2.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9491\n",
      "INFO:tensorflow:loss = 35.320843, step = 9501 (2.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.5342\n",
      "INFO:tensorflow:loss = 29.726202, step = 9601 (2.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.7625\n",
      "INFO:tensorflow:loss = 53.974762, step = 9701 (2.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.4125\n",
      "INFO:tensorflow:loss = 38.003708, step = 9801 (2.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 47.8801\n",
      "INFO:tensorflow:loss = 29.284626, step = 9901 (2.097 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 29.816307.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x138656c88>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearClassifier.train(input_fn=linear_input_fn,steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: HashedCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0/model.ckpt.\n",
      "INFO:tensorflow:loss = 303.92816, step = 1\n",
      "INFO:tensorflow:global_step/sec: 17.0068\n",
      "INFO:tensorflow:loss = 40.18817, step = 101 (5.876 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.9242\n",
      "INFO:tensorflow:loss = 43.90975, step = 201 (3.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4066\n",
      "INFO:tensorflow:loss = 26.708557, step = 301 (4.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.596\n",
      "INFO:tensorflow:loss = 31.1777, step = 401 (4.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.5632\n",
      "INFO:tensorflow:loss = 40.668274, step = 501 (3.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.6461\n",
      "INFO:tensorflow:loss = 72.06564, step = 601 (3.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.2761\n",
      "INFO:tensorflow:loss = 32.796158, step = 701 (4.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0156\n",
      "INFO:tensorflow:loss = 28.99456, step = 801 (4.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.0778\n",
      "INFO:tensorflow:loss = 33.126995, step = 901 (4.983 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6753\n",
      "INFO:tensorflow:loss = 25.5819, step = 1001 (4.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.4477\n",
      "INFO:tensorflow:loss = 28.996586, step = 1101 (5.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9784\n",
      "INFO:tensorflow:loss = 42.72039, step = 1201 (5.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.3068\n",
      "INFO:tensorflow:loss = 42.09439, step = 1301 (5.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4214\n",
      "INFO:tensorflow:loss = 38.022423, step = 1401 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5266\n",
      "INFO:tensorflow:loss = 42.68218, step = 1501 (3.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0601\n",
      "INFO:tensorflow:loss = 30.542671, step = 1601 (3.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.6607\n",
      "INFO:tensorflow:loss = 26.439068, step = 1701 (6.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2553\n",
      "INFO:tensorflow:loss = 31.943945, step = 1801 (9.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.7109\n",
      "INFO:tensorflow:loss = 49.604828, step = 1901 (5.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3618\n",
      "INFO:tensorflow:loss = 34.197273, step = 2001 (4.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.0388\n",
      "INFO:tensorflow:loss = 27.45691, step = 2101 (3.979 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.7771\n",
      "INFO:tensorflow:loss = 31.392746, step = 2201 (3.861 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0237\n",
      "INFO:tensorflow:loss = 31.023785, step = 2301 (3.704 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3618\n",
      "INFO:tensorflow:loss = 32.487923, step = 2401 (3.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4662\n",
      "INFO:tensorflow:loss = 29.99794, step = 2501 (6.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.0176\n",
      "INFO:tensorflow:loss = 25.71708, step = 2601 (5.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2357\n",
      "INFO:tensorflow:loss = 35.022415, step = 2701 (3.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.4885\n",
      "INFO:tensorflow:loss = 27.420113, step = 2801 (3.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0637\n",
      "INFO:tensorflow:loss = 28.730278, step = 2901 (3.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2725\n",
      "INFO:tensorflow:loss = 31.78804, step = 3001 (3.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.9756\n",
      "INFO:tensorflow:loss = 34.252274, step = 3101 (3.576 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.2611\n",
      "INFO:tensorflow:loss = 19.816273, step = 3201 (3.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.729\n",
      "INFO:tensorflow:loss = 23.96155, step = 3301 (3.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8926\n",
      "INFO:tensorflow:loss = 34.41795, step = 3401 (4.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4884\n",
      "INFO:tensorflow:loss = 29.088333, step = 3501 (4.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8458\n",
      "INFO:tensorflow:loss = 28.48759, step = 3601 (3.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3545\n",
      "INFO:tensorflow:loss = 36.69652, step = 3701 (3.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.5088\n",
      "INFO:tensorflow:loss = 34.16533, step = 3801 (3.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1925\n",
      "INFO:tensorflow:loss = 34.86548, step = 3901 (3.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 28.1958\n",
      "INFO:tensorflow:loss = 34.104156, step = 4001 (3.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4887\n",
      "INFO:tensorflow:loss = 28.766909, step = 4101 (4.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2192\n",
      "INFO:tensorflow:loss = 33.652054, step = 4201 (4.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 19.8298\n",
      "INFO:tensorflow:loss = 33.886578, step = 4301 (5.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7107\n",
      "INFO:tensorflow:loss = 34.570496, step = 4401 (6.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 17.4173\n",
      "INFO:tensorflow:loss = 28.676668, step = 4501 (5.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 18.9657\n",
      "INFO:tensorflow:loss = 38.211723, step = 4601 (5.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.2418\n",
      "INFO:tensorflow:loss = 27.54808, step = 4701 (4.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.6019\n",
      "INFO:tensorflow:loss = 27.998657, step = 4801 (4.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.5279\n",
      "INFO:tensorflow:loss = 26.770185, step = 4901 (3.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0055\n",
      "INFO:tensorflow:loss = 32.13472, step = 5001 (4.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.8803\n",
      "INFO:tensorflow:loss = 28.81483, step = 5101 (4.019 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.8785\n",
      "INFO:tensorflow:loss = 44.251457, step = 5201 (3.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1249\n",
      "INFO:tensorflow:loss = 40.947426, step = 5301 (4.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.8299\n",
      "INFO:tensorflow:loss = 26.632668, step = 5401 (3.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.3237\n",
      "INFO:tensorflow:loss = 39.05819, step = 5501 (3.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.9797\n",
      "INFO:tensorflow:loss = 37.235493, step = 5601 (3.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.4271\n",
      "INFO:tensorflow:loss = 29.732584, step = 5701 (3.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6127\n",
      "INFO:tensorflow:loss = 26.230516, step = 5801 (4.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.6029\n",
      "INFO:tensorflow:loss = 39.244144, step = 5901 (3.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.1291\n",
      "INFO:tensorflow:loss = 30.660084, step = 6001 (3.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3757\n",
      "INFO:tensorflow:loss = 31.21982, step = 6101 (4.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.2548\n",
      "INFO:tensorflow:loss = 34.495903, step = 6201 (3.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6519\n",
      "INFO:tensorflow:loss = 45.159138, step = 6301 (4.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.363\n",
      "INFO:tensorflow:loss = 34.33509, step = 6401 (6.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8869\n",
      "INFO:tensorflow:loss = 36.022343, step = 6501 (6.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.0565\n",
      "INFO:tensorflow:loss = 34.323524, step = 6601 (3.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5974\n",
      "INFO:tensorflow:loss = 27.34062, step = 6701 (2.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5975\n",
      "INFO:tensorflow:loss = 25.223188, step = 6801 (2.525 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 39.1726\n",
      "INFO:tensorflow:loss = 24.588888, step = 6901 (2.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4398\n",
      "INFO:tensorflow:loss = 29.368475, step = 7001 (2.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.706\n",
      "INFO:tensorflow:loss = 38.87306, step = 7101 (2.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8698\n",
      "INFO:tensorflow:loss = 32.3413, step = 7201 (2.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8354\n",
      "INFO:tensorflow:loss = 27.243534, step = 7301 (2.715 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5172\n",
      "INFO:tensorflow:loss = 31.030674, step = 7401 (2.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.8431\n",
      "INFO:tensorflow:loss = 35.18019, step = 7501 (2.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6082\n",
      "INFO:tensorflow:loss = 45.310753, step = 7601 (2.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7946\n",
      "INFO:tensorflow:loss = 27.252586, step = 7701 (2.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7049\n",
      "INFO:tensorflow:loss = 27.85239, step = 7801 (2.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8279\n",
      "INFO:tensorflow:loss = 28.593765, step = 7901 (2.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.6869\n",
      "INFO:tensorflow:loss = 37.398346, step = 8001 (2.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.7283\n",
      "INFO:tensorflow:loss = 33.030872, step = 8101 (2.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6752\n",
      "INFO:tensorflow:loss = 20.368172, step = 8201 (2.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1126\n",
      "INFO:tensorflow:loss = 32.248844, step = 8301 (2.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.4522\n",
      "INFO:tensorflow:loss = 38.91433, step = 8401 (2.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3191\n",
      "INFO:tensorflow:loss = 25.791698, step = 8501 (2.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.8487\n",
      "INFO:tensorflow:loss = 23.223679, step = 8601 (2.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5755\n",
      "INFO:tensorflow:loss = 25.654728, step = 8701 (2.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.9916\n",
      "INFO:tensorflow:loss = 24.983526, step = 8801 (2.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7331\n",
      "INFO:tensorflow:loss = 48.505646, step = 8901 (2.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1204\n",
      "INFO:tensorflow:loss = 34.33496, step = 9001 (2.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.1276\n",
      "INFO:tensorflow:loss = 24.540415, step = 9101 (2.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.5638\n",
      "INFO:tensorflow:loss = 27.488825, step = 9201 (3.071 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6977\n",
      "INFO:tensorflow:loss = 28.039888, step = 9301 (2.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7198\n",
      "INFO:tensorflow:loss = 26.461006, step = 9401 (2.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.2038\n",
      "INFO:tensorflow:loss = 23.448826, step = 9501 (2.924 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9454\n",
      "INFO:tensorflow:loss = 21.840084, step = 9601 (3.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.3107\n",
      "INFO:tensorflow:loss = 62.735825, step = 9701 (3.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.3397\n",
      "INFO:tensorflow:loss = 22.45826, step = 9801 (2.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8875\n",
      "INFO:tensorflow:loss = 26.590591, step = 9901 (2.950 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 28.137684.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x13866d2b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnClassifier.train(input_fn=dnn_input_fn,steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,\n",
    "                                                    y=y_test,\n",
    "                                                    batch_size=10,\n",
    "                                                    num_epochs=1, \n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T01:48:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/Slimn/anaconda3/envs/tfdl/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-01:48:58\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.85402805, accuracy_baseline = 0.7611833, auc = 0.9052077, auc_precision_recall = 0.96720517, average_loss = 0.33196247, global_step = 10000, label/mean = 0.7611833, loss = 3.319285, precision = 0.86592793, prediction/mean = 0.8018688, recall = 0.9562937\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "linear_result = linearClassifier.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T01:49:01Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-01:49:13\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.8575084, accuracy_baseline = 0.7611833, auc = 0.9103053, auc_precision_recall = 0.9698105, average_loss = 0.31547186, global_step = 10000, label/mean = 0.7611833, loss = 3.1543956, precision = 0.881662, prediction/mean = 0.7634324, recall = 0.9388112\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "dnn_result = dnnClassifier.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.85402805,\n",
       " 'accuracy_baseline': 0.7611833,\n",
       " 'auc': 0.9052077,\n",
       " 'auc_precision_recall': 0.96720517,\n",
       " 'average_loss': 0.33196247,\n",
       " 'label/mean': 0.7611833,\n",
       " 'loss': 3.319285,\n",
       " 'precision': 0.86592793,\n",
       " 'prediction/mean': 0.8018688,\n",
       " 'recall': 0.9562937,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8575084,\n",
       " 'accuracy_baseline': 0.7611833,\n",
       " 'auc': 0.9103053,\n",
       " 'auc_precision_recall': 0.9698105,\n",
       " 'average_loss': 0.31547186,\n",
       " 'label/mean': 0.7611833,\n",
       " 'loss': 3.1543956,\n",
       " 'precision': 0.881662,\n",
       " 'prediction/mean': 0.7634324,\n",
       " 'recall': 0.9388112,\n",
       " 'global_step': 10000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(x=X_test, \n",
    "                                                       batch_size=len(X_test), \n",
    "                                                       shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmpls4d7ab2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "linear_predictions = list(linearClassifier.predict(input_fn=predict_input_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/j8/4vht5fhd3rg9wv8rx18tt20c0000gp/T/tmp8f3_8vf0/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "dnn_predictions = list(dnnClassifier.predict(input_fn=predict_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([1.3011456], dtype=float32),\n",
       " 'logistic': array([0.78602767], dtype=float32),\n",
       " 'probabilities': array([0.2139723, 0.7860277], dtype=float32),\n",
       " 'class_ids': array([1]),\n",
       " 'classes': array([b'1'], dtype=object)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([0.8584721], dtype=float32),\n",
       " 'logistic': array([0.7023413], dtype=float32),\n",
       " 'probabilities': array([0.29765868, 0.7023414 ], dtype=float32),\n",
       " 'class_ids': array([1]),\n",
       " 'classes': array([b'1'], dtype=object)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a list of only the class_ids key values from the prediction list of dictionaries, these are the predictions you will use to compare against the real y_test values. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predict_result = []\n",
    "for predict in linear_predictions:\n",
    "    linear_predict_result.append(predict['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_predict_result = []\n",
    "for predict in dnn_predictions:\n",
    "    dnn_predict_result.append(predict['class_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_predict_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_predict_result[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.53      0.63      2333\n",
      "           1       0.87      0.96      0.91      7436\n",
      "\n",
      "    accuracy                           0.85      9769\n",
      "   macro avg       0.83      0.74      0.77      9769\n",
      "weighted avg       0.85      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, linear_predict_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67      2333\n",
      "           1       0.88      0.94      0.91      7436\n",
      "\n",
      "    accuracy                           0.86      9769\n",
      "   macro avg       0.82      0.77      0.79      9769\n",
      "weighted avg       0.85      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dnn_predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
